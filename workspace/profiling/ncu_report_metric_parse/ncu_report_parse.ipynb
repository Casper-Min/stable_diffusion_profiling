{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "site.addsitedir(\"/opt/nvidia/nsight-compute/2023.1.1/extras/python\")\n",
    "site.addsitedir(\"/opt/nvidia/nsight-compute/2023.1.1/sections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ncu_report\n",
    "from ncu_report import IMetric\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = ncu_report.load_report(f\"A100_only_attention_prompt1_iter1_step5_replay_kernel_huggingface/A100_only_attention_prompt1_iter1_step5_replay_kernel_huggingface.ncu-rep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = report[0]\n",
    "metric_kernel = kernels[0]\n",
    "metrics = [metric_kernel[name] for name in metric_kernel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes_list = [(\"1_Qu\",\"2_Ke\",\"3_Va\"),(\"5-1_MatMul_Query_Key_Then_Scale\"),(\"5-2_Softmax_score\"),(\"5-3_MatMul_Softmax_Value\"),(\"7_Out_Linear\"),(\"1_Projection\"),(\"Linear\"),(\"1_Q\",\"2_K\",\"3_V\",\"5-1_MatMul_Query_Key_Then_Scale\", \"5-2_Softmax_score\",\"5-3_MatMul_Softmax_Value\",\"7_Out_Linear\",\"1_Projection\",\"Linear\")]\n",
    "# yes_list = [(\"1_Qu\",\"2_Ke\",\"3_Va\"),(\"5-1_MatMul_Query_Key_Then_Scale\"),(\"5-2_Softmax_score\"),(\"5-3_MatMul_Softmax_Value\"),(\"7_Out_Linear\"),(\"1_Projection\"),(\"Linear\")]\n",
    "# yes_list = [(\"1_Q\",\"2_K\",\"3_V\",\"5-1_MatMul_Query_Key_Then_Scale\", \"5-2_Softmax_score\",\"5-3_MatMul_Softmax_Value\",\"7_Out_Linear\",\"1_Projection\",\"Linear\")]\n",
    "# yes_list = (\"1_Q\",\"2_K\",\"3_V\",\"5-1_MatMul_Query_Key_Then_Scale\", \"5-2_Softmax_score\",\"5-3_MatMul_Softmax_Value\",\"7_Out_Linear\",\"1_Projection\",\"Linear\")\n",
    "yes_list = (\"1_Q\",\"2_K\",\"3_V\",\"5-1_MatMul_Query_Key_Then_Scale\",\"5-3_MatMul_Softmax_Value\",\"7_Out_Linear\",\"1_GEGLU\",\"Linear_\")\n",
    "no_list = (\"splitKreduce_kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ampere_sgemm_128x128_tn\n"
     ]
    }
   ],
   "source": [
    "kernel = kernels[13]\n",
    "print(kernel.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncu_prof nsys_prof\n"
     ]
    }
   ],
   "source": [
    "nvtx_info = kernel.nvtx_state()\n",
    "print(nvtx_info[1],nvtx_info[2]) # nvtx_info[0] : default domain, nvtx_info[1] : ncu_prof, nvtx_info[2] : nsys_prof\n",
    "nvtx_domain_ncu_prof = kernel.nvtx_state()[1]\n",
    "nvtx_domain_nsys_prof = kernel.nvtx_state()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('denoising network', 'denoising_step_2', 'noise_prediction_2', 'U-Net', 'contracting_path', '1_CrossAttnDownBlock2D_input_NCHW_2_320_64_64_embedding_2_77_768', 'Transformer2DModel_head(num/dim)8/40_ch(in/out)320/320', 'transformer_computation', 'transformer_BasicTransformerBlock', '2_self_attn_Attention', '5_Scaled Dot Product Attention_Q16_4096_40_K16_4096_40', '5-1_MatMul_Query_Key_Then_Scale_Q16_4096_40_KT16_40_4096')\n",
      "('denoiser_step_2', 'unet_block_1', 'attn_block_2')\n"
     ]
    }
   ],
   "source": [
    "print(nvtx_domain_nsys_prof.push_pop_ranges())\n",
    "print(nvtx_domain_ncu_prof.start_end_ranges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_preprocess RowwiseMomentsCUDAKernel 56.4 4.2E+07 10.5 0.8 186.1 9.4 5.2\n",
      "transformer_preprocess ComputeFusedParamsCUDAKernel 5.3 1.9E+03 0.0 0.0 0.6 0.1 0.3\n",
      "transformer_preprocess elementwise_kernel 19.9 5.2E+06 10.5 0.3 527.1 48.4 24.6\n",
      "transformer_preprocess Kernel 45.3 2.6E+06 10.9 0.1 240.5 46.8 43.0\n",
      "transformer_preprocess elementwise_kernel 20.0 5.2E+06 10.5 0.3 523.5 51.6 23.9\n",
      "1_LayerNorm elementwise_kernel 45.3 0.0E+00 10.6 0.0 233.6 18.7 76.4\n",
      "1_LayerNorm vectorized_layer_norm_kernel 36.9 1.0E+08 10.5 2.7 284.4 69.5 44.8\n",
      "1_Query_Linear_2_4096_320_out_320 ampere_sgemm_32x128_tn 139.8 1.7E+09 11.0 12.1 78.4 81.8 80.1\n",
      "2_Key_Linear_2_4096_320_out_320 ampere_sgemm_32x128_tn 141.6 1.7E+09 11.0 11.9 78.0 82.0 80.2\n",
      "3_Value_Linear_2_4096_320_out_320 ampere_sgemm_32x128_tn 140.0 1.7E+09 11.0 12.1 78.6 82.0 80.2\n",
      "4_Multi-head elementwise_kernel 21.1 0.0E+00 10.5 0.0 498.2 51.1 25.5\n",
      "4_Multi-head elementwise_kernel 20.9 0.0E+00 10.5 0.0 505.4 50.5 25.2\n",
      "4_Multi-head elementwise_kernel 21.0 0.0E+00 10.5 0.0 501.8 50.9 25.4\n",
      "5-1_MatMul_Query_Key_Then_Scale_Q16_4096_40_KT16_40_4096 ampere_sgemm_128x128_tn 1801.4 2.2E+10 1074.8 12.1 596.6 81.4 48.5\n",
      "5-2_Softmax_score_16_4096_4096 cunn_SoftMaxForward 1761.8 8.9E+09 2130.9 5.0 1209.5 60.5 32.3\n",
      "5-3_MatMul_Softmax_Value_SM16_4096_4096_V16_4096_40 ampere_sgemm_128x128_nn 4940.0 6.9E+10 1107.2 13.9 224.1 93.1 33.8\n",
      "6_Concat_Multi-head_input16_4096_40 elementwise_kernel 21.6 0.0E+00 10.5 0.0 486.7 49.9 24.7\n",
      "7_Out_Linear_Projection_input2_4096_320 ampere_sgemm_32x128_tn 171.2 1.7E+09 10.9 9.8 63.7 70.7 66.4\n",
      "9_Out_Rescale vectorized_elementwise_kernel 14.2 2.6E+06 10.5 0.2 739.7 7.6 35.1\n",
      "2_self_attn_Attention elementwise_kernel 47.4 5.2E+06 23.2 0.1 490.7 20.8 78.4\n",
      "3_LayerNorm vectorized_layer_norm_kernel 38.1 1.0E+08 10.5 2.7 275.5 69.5 44.7\n",
      "1_Query_Linear_2_4096_320_out_320 ampere_sgemm_32x128_tn 141.6 1.7E+09 11.1 11.9 78.3 82.2 80.4\n",
      "2_Key_Linear_2_77_768_out_320 ampere_sgemm_32x32_sliced1x4_tn 19.0 8.0E+07 1.5 4.2 76.6 31.3 38.9\n",
      "2_Key_Linear_2_77_768_out_320 splitKreduce_kernel 6.1 2.5E+05 0.8 0.0 129.7 7.6 6.2\n",
      "3_Value_Linear_2_77_768_out_320 ampere_sgemm_32x32_sliced1x4_tn 18.9 8.0E+07 1.5 4.2 77.0 31.5 39.1\n",
      "3_Value_Linear_2_77_768_out_320 splitKreduce_kernel 6.2 2.5E+05 0.8 0.0 127.0 7.6 6.2\n",
      "4_Multi-head elementwise_kernel 21.0 0.0E+00 10.6 0.0 502.1 50.6 25.3\n",
      "4_Multi-head elementwise_kernel 6.9 0.0E+00 0.2 0.0 28.7 3.7 2.6\n",
      "4_Multi-head elementwise_kernel 6.9 0.0E+00 0.2 0.0 28.7 3.7 2.5\n",
      "5-1_MatMul_Query_Key_Then_Scale_Q16_4096_40_KT16_40_77 ampere_sgemm_128x128_tn 69.7 6.8E+08 12.0 9.8 171.7 68.1 39.7\n",
      "5-2_Softmax_score_16_4096_77 softmax_warp_forward 35.5 1.6E+08 25.9 4.6 729.9 69.7 39.4\n",
      "5-3_MatMul_Softmax_Value_SM16_4096_77_V16_77_40 ampere_sgemm_128x128_nn 113.9 1.4E+09 20.5 11.9 179.9 80.2 38.9\n",
      "6_Concat_Multi-head_input16_4096_40 elementwise_kernel 21.1 0.0E+00 10.5 0.0 498.6 50.1 24.9\n",
      "7_Out_Linear_Projection_input2_4096_320 ampere_sgemm_32x128_tn 168.4 1.7E+09 10.9 10.0 64.8 69.7 65.5\n",
      "9_Out_Rescale vectorized_elementwise_kernel 14.3 2.6E+06 10.5 0.2 734.7 7.7 36.0\n",
      "4_crs_attn_Attention vectorized_elementwise_kernel 20.5 5.2E+06 21.3 0.3 1038.8 5.8 46.3\n",
      "5_LayerNorm vectorized_layer_norm_kernel 37.8 1.0E+08 10.5 2.7 277.9 69.4 44.6\n",
      "1_GEGLU_Linear_IO_320_2560 ampere_sgemm_128x64_tn 944.7 1.3E+10 77.7 14.3 82.3 95.0 50.3\n",
      "GELU elementwise_kernel 76.3 2.0E+08 69.1 2.6 906.6 65.6 27.2\n",
      "2_GATE_GELU elementwise_kernel 90.0 1.0E+07 115.8 0.1 1286.1 34.6 37.1\n",
      "Linear_1280_320 ampere_sgemm_32x128_tn 536.6 6.7E+09 49.7 12.5 92.7 83.6 75.8\n",
      "6_FF_FeedForward vectorized_elementwise_kernel 20.4 5.2E+06 21.3 0.3 1044.2 5.7 45.0\n",
      "transformer_postprocess elementwise_kernel 44.9 0.0E+00 10.8 0.0 240.4 19.0 79.7\n",
      "transformer_postprocess Kernel 43.9 2.6E+06 10.9 0.1 248.3 49.0 44.9\n",
      "transformer_postprocess elementwise_kernel 20.2 5.2E+06 10.5 0.3 520.2 51.3 23.9\n",
      "transformer_postprocess vectorized_elementwise_kernel 20.4 5.2E+06 21.1 0.3 1034.5 5.8 46.1\n"
     ]
    }
   ],
   "source": [
    "Execution_Time_t=0\n",
    "Executed_Inst_t=0\n",
    "Total_Traffic_t=0\n",
    "\n",
    "for kernel in kernels:\n",
    "    # range_name = nvtx_info.push_pop_ranges()[6] # 6 Resnet/Transformer Block Level\n",
    "    nvtx_domain_ncu_prof = kernel.nvtx_state()[1]\n",
    "    nvtx_domain_nsys_prof = kernel.nvtx_state()[2]\n",
    "    ncu_range_name = nvtx_domain_ncu_prof.start_end_ranges()[1]\n",
    "    nsys_range_name = nvtx_domain_nsys_prof.push_pop_ranges()[-1]\n",
    "    if ncu_range_name == \"unet_block_1\":\n",
    "        # print(range_name)\n",
    "        Work_Achieved = (kernel[\"smsp__sass_thread_inst_executed_op_fadd_pred_on.sum.per_cycle_elapsed\"].value()\\\n",
    "                        + kernel[\"smsp__sass_thread_inst_executed_op_fmul_pred_on.sum.per_cycle_elapsed\"].value()\\\n",
    "                        + kernel[\"derived__smsp__sass_thread_inst_executed_op_ffma_pred_on_x2\"].value()) \\\n",
    "                        * kernel[\"smsp__cycles_elapsed.avg.per_second\"].value()\n",
    "        Traffic_Achieved = kernel[\"dram__bytes.sum.per_second\"].value()                \n",
    "        inst = kernel[\"thread_inst_executed\"].value()\n",
    "        inst2 = kernel[\"inst_executed\"].value()\n",
    "        Execution_Time = kernel[\"gpu__time_duration.sum\"].value()\n",
    "        Executed_Inst = Work_Achieved * Execution_Time * 0.000000001\n",
    "        Total_Traffic = Traffic_Achieved * Execution_Time * 0.000000001\n",
    "        Execution_Time_t += Execution_Time\n",
    "        Executed_Inst_t += Executed_Inst\n",
    "        Total_Traffic_t += Total_Traffic\n",
    "        \n",
    "        Work_Achieved = Work_Achieved/(1000000000000)\n",
    "        Traffic_Achieved = Traffic_Achieved/(1000000000)\n",
    "        \n",
    "        SM_BUSY = kernel[\"sm__throughput.avg.pct_of_peak_sustained_elapsed\"].value()\n",
    "        MEM_BUSY = kernel[\"gpu__compute_memory_access_throughput.avg.pct_of_peak_sustained_elapsed\"].value()\n",
    "        \n",
    "        # print(f\"{nsys_range_name} {kernel.name()} {Executed_Inst:.1f} {Total_Traffic/(1000*1000):.2f} , {Execution_Time/1000000}\")\n",
    "        print(f\"{nsys_range_name} {kernel.name()} {Execution_Time/1000:.1f} {Executed_Inst:.1E} {Total_Traffic/(1000*1000):.1f} {Work_Achieved:.1f} {Traffic_Achieved:.1f} {SM_BUSY:.1f} {MEM_BUSY:.1f}\")\n",
    "        # print(f\"{Execution_Time_t:.2E}\")\n",
    "        # print(f\"{Executed_Inst_t:.2E}\")\n",
    "        # print(f\"{Total_Traffic_t:.2E}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ampere_sgemm_32x128_tn 139.8 1.7E+09 11.0 12.1 78.4 81.8 80.1\n",
      "ampere_sgemm_32x128_tn 141.6 1.7E+09 11.0 11.9 78.0 82.0 80.2\n",
      "ampere_sgemm_32x128_tn 140.0 1.7E+09 11.0 12.1 78.6 82.0 80.2\n",
      "ampere_sgemm_128x128_tn 1801.4 2.2E+10 1074.8 12.1 596.6 81.4 48.5\n",
      "ampere_sgemm_128x128_nn 4940.0 6.9E+10 1107.2 13.9 224.1 93.1 33.8\n",
      "ampere_sgemm_32x128_tn 171.2 1.7E+09 10.9 9.8 63.7 70.7 66.4\n",
      "ampere_sgemm_32x128_tn 141.6 1.7E+09 11.1 11.9 78.3 82.2 80.4\n",
      "ampere_sgemm_32x32_sliced1x4_tn 19.0 8.0E+07 1.5 4.2 76.6 31.3 38.9\n",
      "ampere_sgemm_32x32_sliced1x4_tn 18.9 8.0E+07 1.5 4.2 77.0 31.5 39.1\n",
      "ampere_sgemm_128x128_tn 69.7 6.8E+08 12.0 9.8 171.7 68.1 39.7\n",
      "ampere_sgemm_128x128_nn 113.9 1.4E+09 20.5 11.9 179.9 80.2 38.9\n",
      "ampere_sgemm_32x128_tn 168.4 1.7E+09 10.9 10.0 64.8 69.7 65.5\n",
      "ampere_sgemm_128x64_tn 944.7 1.3E+10 77.7 14.3 82.3 95.0 50.3\n",
      "ampere_sgemm_32x128_tn 536.6 6.7E+09 49.7 12.5 92.7 83.6 75.8\n"
     ]
    }
   ],
   "source": [
    "# Execution_Time_t=0\n",
    "# Executed_Inst_t=0\n",
    "# Total_Traffic_t=0\n",
    "\n",
    "# for kernel in kernels:\n",
    "#     # range_name = nvtx_info.push_pop_ranges()[6] # 6 Resnet/Transformer Block Level\n",
    "#     nvtx_domain_ncu_prof = kernel.nvtx_state()[1]\n",
    "#     nvtx_domain_nsys_prof = kernel.nvtx_state()[2]\n",
    "#     ncu_range_name = nvtx_domain_ncu_prof.start_end_ranges()[1]\n",
    "#     nsys_range_name = nvtx_domain_nsys_prof.push_pop_ranges()[-1]\n",
    "#     if ncu_range_name == \"unet_block_1\":\n",
    "#         if nsys_range_name.startswith(yes_list) :\n",
    "#             if not kernel.name().startswith(no_list) :\n",
    "#                 # print(range_name)\n",
    "#                 Work_Achieved = (kernel[\"smsp__sass_thread_inst_executed_op_fadd_pred_on.sum.per_cycle_elapsed\"].value()\\\n",
    "#                                 + kernel[\"smsp__sass_thread_inst_executed_op_fmul_pred_on.sum.per_cycle_elapsed\"].value()\\\n",
    "#                                 + kernel[\"derived__smsp__sass_thread_inst_executed_op_ffma_pred_on_x2\"].value()) \\\n",
    "#                                 * kernel[\"smsp__cycles_elapsed.avg.per_second\"].value()\n",
    "#                 Traffic_Achieved = kernel[\"dram__bytes.sum.per_second\"].value()                \n",
    "#                 inst = kernel[\"thread_inst_executed\"].value()\n",
    "#                 inst2 = kernel[\"inst_executed\"].value()\n",
    "#                 Execution_Time = kernel[\"gpu__time_duration.sum\"].value()\n",
    "#                 Executed_Inst = Work_Achieved * Execution_Time * 0.000000001\n",
    "#                 Total_Traffic = Traffic_Achieved * Execution_Time * 0.000000001\n",
    "#                 Execution_Time_t += Execution_Time\n",
    "#                 Executed_Inst_t += Executed_Inst\n",
    "#                 Total_Traffic_t += Total_Traffic\n",
    "                \n",
    "#                 Work_Achieved = Work_Achieved/(1000000000000)\n",
    "#                 Traffic_Achieved = Traffic_Achieved/(1000000000)\n",
    "                \n",
    "#                 SM_BUSY = kernel[\"sm__throughput.avg.pct_of_peak_sustained_elapsed\"].value()\n",
    "#                 MEM_BUSY = kernel[\"gpu__compute_memory_access_throughput.avg.pct_of_peak_sustained_elapsed\"].value()\n",
    "                \n",
    "#                 # print(f\"{nsys_range_name} {kernel.name()} {Executed_Inst:.1f} {Total_Traffic/(1000*1000):.2f} , {Execution_Time/1000000}\")\n",
    "#                 print(f\"{kernel.name()} {Execution_Time/1000:.1f} {Executed_Inst:.1E} {Total_Traffic/(1000*1000):.1f} {Work_Achieved:.1f} {Traffic_Achieved:.1f} {SM_BUSY:.1f} {MEM_BUSY:.1f}\")\n",
    "#                 # print(f\"{Execution_Time_t:.2E}\")\n",
    "#                 # print(f\"{Executed_Inst_t:.2E}\")\n",
    "#                 # print(f\"{Total_Traffic_t:.2E}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd_profile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
